from flask import Blueprint, request, jsonify
from services.ai_service import ai_service
from services.qdrant_service import qdrant_service
from models.employee import ChatRequest, ChatResponse, EmbeddingRequest, EmbeddingResponse, ContextRequest, ContextResponse
import logging
import json
import re
from datetime import datetime

logger = logging.getLogger(__name__)

chat_bp = Blueprint('chat', __name__)

@chat_bp.route('/chat', methods=['POST'])
def chat():
    """GeliÅŸmiÅŸ chat completion endpoint - Web uygulamasÄ± yaklaÅŸÄ±mÄ±"""
    try:
        data = request.get_json()
        chat_request = ChatRequest(**data)

        # Chat history'yi al (varsa)
        history = data.get('history', [])
        
        logger.info(f"Chat isteÄŸi: {chat_request.question}")

        # 1. KullanÄ±cÄ± mesajÄ±ndan embedding oluÅŸtur
        embedding_result = ai_service.generate_embedding(chat_request.question)
        if not embedding_result["success"]:
            logger.error("Embedding oluÅŸturulamadÄ±")
            return jsonify({
                "answer": "ÃœzgÃ¼nÃ¼m, mesajÄ±nÄ±zÄ± iÅŸleyemedim. LÃ¼tfen tekrar deneyin.",
                "success": False,
                "error": "EMBEDDING_FAILED"
            }), 500
        
        embedding = embedding_result["embedding"]
        
        # 2. Smart Query Detection - HÄ±zlÄ± analiz iÃ§in
        query_lower = chat_request.question.lower()
        needs_all_data = any(keyword in query_lower for keyword in [
            'en Ã§ok', 'en fazla', 'en yÃ¼ksek', 'sÄ±rala', 'listele', 'tÃ¼m', 'hepsi', 
            'karÅŸÄ±laÅŸtÄ±r', 'ortalama', 'toplam', 'kimler', 'hangi', 'kaÃ§ kiÅŸi'
        ])
        
        context = ''
        context_used = False
        relevant_sources = []
        
        if needs_all_data:
            # TÃœM VERÄ°LERÄ° AL - DOÄžRU ANALÄ°Z Ä°Ã‡Ä°N
            logger.info("ðŸš€ TÃ¼m veriler alÄ±nÄ±yor (doÄŸru analiz iÃ§in)...")
            try:
                all_employees = qdrant_service.list_employees()
                logger.info(f"ðŸ“Š Toplam Ã§alÄ±ÅŸan sayÄ±sÄ±: {len(all_employees)}")
                
                # Mesai saatlerine gÃ¶re sÄ±rala
                employee_hours = []
                for emp in all_employees:
                    toplam_mesai_list = emp.get('toplam_mesai', [])
                    toplam_saat = sum(toplam_mesai_list) if toplam_mesai_list else 0
                    employee_hours.append({
                        'isim': emp.get('isim', 'Bilinmeyen'),
                        'toplam_saat': toplam_saat,
                        'hafta_sayisi': len(toplam_mesai_list)
                    })
                
                # YÃ¼ksekten dÃ¼ÅŸÃ¼ÄŸe sÄ±rala
                employee_hours.sort(key=lambda x: x['toplam_saat'], reverse=True)
                
                # Context oluÅŸtur - EN FAZLA 10 KÄ°ÅžÄ°
                context_parts = []
                for i, emp in enumerate(employee_hours[:10]):
                    context_parts.append(f"{i+1}. {emp['isim']}: {emp['toplam_saat']} saat")
                    relevant_sources.append({
                        'text': f"{emp['isim']}: {emp['toplam_saat']} saat",
                        'score': 100 - (i * 5)  # SÄ±ralama skorlarÄ±
                    })
                
                context = "MESAI SIRALAMASI (En Ã§oktan en aza):\n" + '\n'.join(context_parts)
                context_used = True
                logger.info(f"âœ… Tam veri analizi hazÄ±r: {len(employee_hours)} Ã§alÄ±ÅŸan")
                
            except Exception as e:
                logger.error(f"TÃ¼m veri alma hatasÄ±: {e}")
                # Fallback to vector search
                context_used = False
        
        if not context_used:
            # VektÃ¶r arama yap (eski metod)
            logger.info("ðŸ” VektÃ¶r arama baÅŸlÄ±yor...")
            search_results = qdrant_service.search_by_embedding(embedding, chat_request.question, limit=8)
            
            if search_results and len(search_results) > 0:
                relevant_results = [
                    result for result in search_results 
                    if result.get('score', 0) > 0.05  # Daha dÃ¼ÅŸÃ¼k threshold
                ][:5]  # En fazla 5 sonuÃ§
                
                if relevant_results:
                    context_parts = []
                    for result in relevant_results:
                        payload = result.get('payload', {})
                        if payload.get('isim'):
                            toplam_mesai_list = payload.get('toplam_mesai', [])
                            toplam_saat = sum(toplam_mesai_list) if toplam_mesai_list else 0
                            
                            text = f"Ã‡alÄ±ÅŸan: {payload['isim']}, Toplam Mesai: {toplam_saat} saat"
                            context_parts.append(text)
                            relevant_sources.append({
                                'text': f"{payload['isim']}: {toplam_saat} saat",
                                'score': round(result.get('score', 0) * 100)
                            })
                    
                    context = '\n'.join(context_parts)
                    context_used = True
                    logger.info(f"Context oluÅŸturuldu: {len(context_parts)} kaynak")
        
        # 4. HIZLI System prompt hazÄ±rla
        if context_used:
            system_prompt = f"""MESAI VERÄ°SÄ°:
{context}

GÃ–REV: Sadece verilen mesai verilerini kullanarak KISA VE NET TÃ¼rkÃ§e yanÄ±t ver.

KURALLAR:
- SADECE TÃœRKÃ‡E YAZ
- MAKSIMUM 1-2 CÃœMLE
- VERÄ°DEKÄ° SIRALAMA DOÄžRU
- Ä°SÄ°M + SAAT formatÄ± kullan

HIZLI YANIT VER!"""
        else:
            # Context yoksa basit bir prompt kullan
            system_prompt = """SEN BÄ°R TÃœRK MESAI UZMANISIIN! SADECE TÃœRKÃ‡E YANIT VER!

Mesai analizi hakkÄ±nda sorulara kÄ±sa ve net TÃ¼rkÃ§e cevaplar ver.

KURALLAR:
- SADECE TÃœRKÃ‡E YAZ
- MAKSIMUM 2 CÃœMLE
- GENEL MESAI BÄ°LGÄ°LERÄ° VER
- Ä°NGÄ°LÄ°ZCE YAZMA

YANIT DÄ°LÄ°: TÃœRKÃ‡E"""
        
        # 5. Chat mesajlarÄ±nÄ± hazÄ±rla
        messages = [
            {
                "role": "system",
                "content": system_prompt
            }
        ]
        
        # Chat history'yi ekle (son 5 mesaj)
        for msg in history[-5:]:
            if msg.get('role') in ['user', 'assistant']:
                messages.append({
                    "role": msg['role'],
                    "content": msg.get('content', '')
                })
        
        # KullanÄ±cÄ± mesajÄ±nÄ± ekle
        messages.append({
            "role": "user",
            "content": chat_request.question
        })
        
        logger.info(f"Chat mesajlarÄ± hazÄ±rlandÄ±: {len(messages)} mesaj")
        
        # 6. ULTRA HIZLI AI yanÄ±tÄ± al
        completion_result = ai_service.generate_completion_with_messages(
            messages,
            temperature=0.0,   # Deterministik yanÄ±tlar (Ã§ok hÄ±zlÄ±)
            max_tokens=50      # Ã‡ok kÄ±sa yanÄ±tlar (maksimum hÄ±z)
        )
        
        if not completion_result["success"]:
            logger.error(f"AI yanÄ±tÄ± alÄ±namadÄ±: {completion_result.get('error', 'Unknown error')}")
            
            # DIRECT ANALYSIS - AI olmadan hÄ±zlÄ± yanÄ±t
            if context_used and relevant_sources:
                # En Ã§ok mesai yapan sorusu iÃ§in direct yanÄ±t
                if 'en Ã§ok' in chat_request.question.lower() or 'en fazla' in chat_request.question.lower():
                    if relevant_sources:
                        top_employee = relevant_sources[0]
                        direct_answer = f"En Ã§ok mesai yapan Ã§alÄ±ÅŸan {top_employee['text']}."
                        
                        return jsonify({
                            "answer": direct_answer,
                            "success": True,
                            "context_used": True,
                            "sources": relevant_sources[:3],
                            "direct_analysis": True
                        }), 200
                
                # Genel fallback
                fallback_answer = f"Veriler bulundu: {', '.join([src['text'] for src in relevant_sources[:3]])}"
                
                return jsonify({
                    "answer": fallback_answer,
                    "success": True,
                    "context_used": True,
                    "sources": relevant_sources,
                    "fallback": True
                }), 200
            
            return jsonify({
                "answer": "AI servisi geÃ§ici olarak yanÄ±t veremiyor. LÃ¼tfen birkaÃ§ saniye sonra tekrar deneyin.",
                "success": False,
                "error": "AI_RESPONSE_FAILED"
            }), 500
        
        ai_response = completion_result["answer"]
        
        # 7. Log'u kaydet
        try:
            log_data = {
                "message": chat_request.question,
                "response": ai_response,
                "timestamp": str(datetime.now()),
                "context_used": context_used,
                "context_length": len(context),
                "sources_count": len(relevant_sources)
            }
            
            # Log dosyasÄ±na kaydet
            with open("logs/chat_logs.json", "a", encoding="utf-8") as f:
                f.write(json.dumps(log_data, ensure_ascii=False) + "\n")
                
        except Exception as log_error:
            logger.warning(f"Log kaydedilemedi: {log_error}")
        
        # 8. YanÄ±tÄ± dÃ¶ndÃ¼r
        response_data = {
            "answer": ai_response,
            "success": True,
            "context_used": context_used,
            "context_info": {
                "sources_count": len(relevant_sources),
                "context_length": len(context)
            }
        }
        
        if relevant_sources:
            response_data["sources"] = relevant_sources
        
        logger.info(f"Chat yanÄ±tÄ± baÅŸarÄ±lÄ±: {len(ai_response)} karakter")

        return jsonify(response_data), 200
        
    except Exception as e:
        logger.error(f"Chat Controller Error: {e}")
        return jsonify({
            "answer": "Bir hata oluÅŸtu. LÃ¼tfen tekrar deneyin.",
            "success": False,
            "error": str(e)
        }), 500

@chat_bp.route('/chat/context', methods=['POST'])
def get_context():
    """Context endpoint (semantic search)"""
    try:
        data = request.get_json()
        context_request = ContextRequest(**data)
        
        context = qdrant_service.search_by_embedding(
            context_request.embedding, 
            context_request.query
        )
        
        response = ContextResponse(context=context)
        return jsonify(response.dict()), 200
        
    except Exception as e:
        logger.error(f"Context Controller Error: {e}")
        
        # Hata durumunda tÃ¼m verileri dÃ¶ndÃ¼r
        try:
            all_employees = qdrant_service.list_employees()
            return jsonify({
                "context": all_employees,
                "success": False,
                "error": "FALLBACK_TO_ALL_DATA"
            }), 200
        except Exception as fallback_err:
            return jsonify({
                "context": [],
                "success": False,
                "error": str(e)
            }), 500

@chat_bp.route('/embedding', methods=['POST'])
def generate_embedding():
    """Embedding endpoint"""
    try:
        data = request.get_json()
        embedding_request = EmbeddingRequest(**data)
        
        result = ai_service.generate_embedding(embedding_request.text)
        
        response = EmbeddingResponse(
            embedding=result["embedding"],
            success=result["success"],
            error=result.get("error")
        )
        
        return jsonify(response.dict()), 200
        
    except Exception as e:
        logger.error(f"Embedding Controller Error: {e}")
        
        # Fallback embedding
        import numpy as np
        fallback_embedding = list(np.random.random(384))
        
        return jsonify({
            "embedding": fallback_embedding,
            "success": False,
            "error": "EMBEDDING_FALLBACK"
        }), 200 