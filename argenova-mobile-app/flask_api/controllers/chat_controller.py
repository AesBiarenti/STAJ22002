from flask import Blueprint, request, jsonify
from services.ai_service import ai_service
from services.qdrant_service import qdrant_service
from models.employee import ChatRequest, ChatResponse, EmbeddingRequest, EmbeddingResponse, ContextRequest, ContextResponse
import logging
import json
import re
from datetime import datetime

logger = logging.getLogger(__name__)

chat_bp = Blueprint('chat', __name__)

@chat_bp.route('/chat', methods=['POST'])
def chat():
    """GeliÅŸmiÅŸ chat completion endpoint - Web uygulamasÄ± yaklaÅŸÄ±mÄ±"""
    try:
        data = request.get_json()
        chat_request = ChatRequest(**data)

        # Chat history'yi al (varsa)
        history = data.get('history', [])
        
        logger.info(f"Chat isteÄŸi: {chat_request.question}")

        # 1. KullanÄ±cÄ± mesajÄ±ndan embedding oluÅŸtur
        embedding_result = ai_service.generate_embedding(chat_request.question)
        if not embedding_result["success"]:
            logger.error("Embedding oluÅŸturulamadÄ±")
            return jsonify({
                "answer": "ÃœzgÃ¼nÃ¼m, mesajÄ±nÄ±zÄ± iÅŸleyemedim. LÃ¼tfen tekrar deneyin.",
                "success": False,
                "error": "EMBEDDING_FAILED"
            }), 500
        
        embedding = embedding_result["embedding"]
        
        # 2. VektÃ¶r veritabanÄ±nda arama yap
        logger.info("ğŸ” VektÃ¶r arama baÅŸlÄ±yor...")
        search_results = qdrant_service.search_by_embedding(embedding, chat_request.question, limit=5)
        
        logger.info(f"ğŸ“Š Arama sonucu sayÄ±sÄ±: {len(search_results) if search_results else 0}")
        
        # 3. Context oluÅŸtur - benzerlik skoruna gÃ¶re filtrele
        context = ''
        context_used = False
        relevant_sources = []
        
        if search_results and len(search_results) > 0:
            # Debug: SkorlarÄ± logla
            for i, result in enumerate(search_results):
                logger.info(f"SonuÃ§ {i+1}: Score={result.get('score', 0)}, Payload={result.get('payload', {}).get('isim', 'N/A')}")
            
            # Benzerlik skoruna gÃ¶re filtrele (0.1 threshold - daha dÃ¼ÅŸÃ¼k)
            relevant_results = [
                result for result in search_results 
                if result.get('score', 0) > 0.1
            ][:3]  # En fazla 3 sonuÃ§ kullan
            
            if relevant_results:
                context_parts = []
                for result in relevant_results:
                    payload = result.get('payload', {})
                    # Ã‡alÄ±ÅŸan verilerini text formatÄ±na Ã§evir (chat.post.ts yaklaÅŸÄ±mÄ±)
                    if payload.get('isim'):
                        # Toplam mesai saatlerini hesapla
                        toplam_mesai_list = payload.get('toplam_mesai', [])
                        toplam_saat = sum(toplam_mesai_list) if toplam_mesai_list else 0
                        
                        # GÃ¼nlÃ¼k mesai detaylarÄ±nÄ± formatla
                        gunluk_mesai_list = payload.get('gunluk_mesai', [])
                        gunluk_detay = ""
                        if gunluk_mesai_list and len(gunluk_mesai_list) > 0:
                            son_hafta = gunluk_mesai_list[-1]  # Son haftanÄ±n verisi
                            gunluk_detay = f"Pazartesi: {son_hafta.get('pazartesi', 0)}h, SalÄ±: {son_hafta.get('sali', 0)}h, Ã‡arÅŸamba: {son_hafta.get('carsamba', 0)}h, PerÅŸembe: {son_hafta.get('persembe', 0)}h, Cuma: {son_hafta.get('cuma', 0)}h"
                        
                        text = f"Ã‡alÄ±ÅŸan: {payload['isim']}, Toplam Mesai: {toplam_saat} saat, GÃ¼nlÃ¼k Mesai: {gunluk_detay}"
                        context_parts.append(text)
                        relevant_sources.append({
                            'text': f"{payload['isim']}: {toplam_saat} saat",
                            'score': round(result.get('score', 0) * 100)
                        })
                
                context = '\n\n'.join(context_parts)
                context_used = True
                logger.info(f"Context oluÅŸturuldu: {len(context_parts)} kaynak")
                logger.info(f"Context iÃ§eriÄŸi: {context[:200]}...")
        
        # 4. System prompt hazÄ±rla
        if context_used:
            system_prompt = f"""Sen geliÅŸmiÅŸ bir mesai analiz asistanÄ±sÄ±n. AÅŸaÄŸÄ±daki gÃ¼venilir Ã§alÄ±ÅŸan verilerini kullanarak kapsamlÄ± analizler yap:

{context}

YETENEKLERÄ°N:
1. **Ã‡alÄ±ÅŸan RaporlarÄ±**: TÃ¼m Ã§alÄ±ÅŸanlar hakkÄ±nda detaylÄ± raporlar oluÅŸtur
2. **Mesai Analizi**: GÃ¼nlÃ¼k, haftalÄ±k, aylÄ±k mesai saatlerini analiz et
3. **SÄ±ralama ve Filtreleme**: Ã‡alÄ±ÅŸanlarÄ± mesai saatlerine gÃ¶re sÄ±rala
4. **Ä°statistiksel Analiz**: Ortalama, en yÃ¼ksek, en dÃ¼ÅŸÃ¼k mesai saatlerini hesapla
5. **KarÅŸÄ±laÅŸtÄ±rma**: Ã‡alÄ±ÅŸanlarÄ± birbirleriyle karÅŸÄ±laÅŸtÄ±r
6. **Trend Analizi**: Mesai trendlerini ve deÄŸiÅŸimleri analiz et
7. **Ã–neriler**: Mesai optimizasyonu iÃ§in Ã¶neriler sun

DETAYLI TALÄ°MATLAR:
- CevabÄ±nÄ± mutlaka TÃ¼rkÃ§e ver
- Sadece verilen bilgileri kullan, uydurma yapma
- KISA VE NET yanÄ±tlar ver (maksimum 3-4 cÃ¼mle)
- SayÄ±sal verileri net gÃ¶ster (saat, yÃ¼zde)
- SÄ±ralama yaparken sadece isim ve mesai saati ver
- Gereksiz aÃ§Ä±klamalar yapma
- EÄŸer bilgi yoksa "Bu bilgi mevcut verilerde bulunmuyor" de
- DoÄŸal ve anlaÅŸÄ±lÄ±r dil kullan

Ã–RNEK SORULAR VE YANITLAR:
- "TÃ¼m Ã§alÄ±ÅŸanlarÄ± mesai saatlerine gÃ¶re sÄ±rala" â†’ "Ahmet: 45 saat, Mehmet: 42 saat, AyÅŸe: 40 saat"
- "En fazla mesai yapan 5 Ã§alÄ±ÅŸanÄ± gÃ¶ster" â†’ "1. Ahmet (45h), 2. Mehmet (42h), 3. AyÅŸe (40h)"
- "Ortalama mesai saatini hesapla" â†’ "Ortalama: 38.5 saat"
- "Mesai saatleri 40'Ä±n Ã¼zerinde olanlarÄ± bul" â†’ "Ahmet (45h), Mehmet (42h)" """
        else:
            system_prompt = """Sen geliÅŸmiÅŸ bir mesai analiz asistanÄ±sÄ±n. Mesai saatleri, Ã§alÄ±ÅŸan verileri ve iÅŸ kurallarÄ± hakkÄ±nda kapsamlÄ± analizler yapabilirsin.

YETENEKLERÄ°N:
1. **Genel Mesai Analizi**: Standart mesai kurallarÄ± ve hesaplamalarÄ±
2. **Ä°statistiksel Bilgiler**: Ortalama mesai, fazla mesai hesaplamalarÄ±
3. **Yasal Bilgiler**: Ä°ÅŸ kanunu ve mesai yÃ¶netmelikleri
4. **Ã–neriler**: Mesai optimizasyonu ve verimlilik artÄ±rma
5. **Raporlama**: FarklÄ± rapor formatlarÄ± ve analiz yÃ¶ntemleri

DETAYLI TALÄ°MATLAR:
- CevabÄ±nÄ± mutlaka TÃ¼rkÃ§e ver
- KISA VE NET yanÄ±tlar ver (maksimum 2-3 cÃ¼mle)
- EÄŸer kesin bilgi yoksa, bunu belirt
- DoÄŸal ve anlaÅŸÄ±lÄ±r dil kullan
- Gereksiz aÃ§Ä±klamalar yapma"""
        
        # 5. Chat mesajlarÄ±nÄ± hazÄ±rla
        messages = [
            {
                "role": "system",
                "content": system_prompt
            }
        ]
        
        # Chat history'yi ekle (son 5 mesaj)
        for msg in history[-5:]:
            if msg.get('role') in ['user', 'assistant']:
                messages.append({
                    "role": msg['role'],
                    "content": msg.get('content', '')
                })
        
        # KullanÄ±cÄ± mesajÄ±nÄ± ekle
        messages.append({
            "role": "user",
            "content": chat_request.question
        })
        
        logger.info(f"Chat mesajlarÄ± hazÄ±rlandÄ±: {len(messages)} mesaj")
        
        # 6. AI yanÄ±tÄ± al
        completion_result = ai_service.generate_completion_with_messages(
            messages,
            temperature=0.2,  # Daha tutarlÄ± yanÄ±tlar iÃ§in
            max_tokens=500    # KÄ±sa yanÄ±tlar iÃ§in
        )
        
        if not completion_result["success"]:
            logger.error("AI yanÄ±tÄ± alÄ±namadÄ±")
            return jsonify({
                "answer": "ÃœzgÃ¼nÃ¼m, ÅŸu anda yanÄ±t veremiyorum. LÃ¼tfen daha sonra tekrar deneyin.",
                "success": False,
                "error": "AI_RESPONSE_FAILED"
            }), 500
        
        ai_response = completion_result["answer"]
        
        # 7. Log'u kaydet
        try:
            log_data = {
                "message": chat_request.question,
                "response": ai_response,
                "timestamp": str(datetime.now()),
                "context_used": context_used,
                "context_length": len(context),
                "sources_count": len(relevant_sources)
            }
            
            # Log dosyasÄ±na kaydet
            with open("logs/chat_logs.json", "a", encoding="utf-8") as f:
                f.write(json.dumps(log_data, ensure_ascii=False) + "\n")
                
        except Exception as log_error:
            logger.warning(f"Log kaydedilemedi: {log_error}")
        
        # 8. YanÄ±tÄ± dÃ¶ndÃ¼r
        response_data = {
            "answer": ai_response,
            "success": True,
            "context_used": context_used,
            "context_info": {
                "sources_count": len(relevant_sources),
                "context_length": len(context)
            }
        }
        
        if relevant_sources:
            response_data["sources"] = relevant_sources
        
        logger.info(f"Chat yanÄ±tÄ± baÅŸarÄ±lÄ±: {len(ai_response)} karakter")

        return jsonify(response_data), 200
        
    except Exception as e:
        logger.error(f"Chat Controller Error: {e}")
        return jsonify({
            "answer": "Bir hata oluÅŸtu. LÃ¼tfen tekrar deneyin.",
            "success": False,
            "error": str(e)
        }), 500

@chat_bp.route('/chat/context', methods=['POST'])
def get_context():
    """Context endpoint (semantic search)"""
    try:
        data = request.get_json()
        context_request = ContextRequest(**data)
        
        context = qdrant_service.search_by_embedding(
            context_request.embedding, 
            context_request.query
        )
        
        response = ContextResponse(context=context)
        return jsonify(response.dict()), 200
        
    except Exception as e:
        logger.error(f"Context Controller Error: {e}")
        
        # Hata durumunda tÃ¼m verileri dÃ¶ndÃ¼r
        try:
            all_employees = qdrant_service.list_employees()
            return jsonify({
                "context": all_employees,
                "success": False,
                "error": "FALLBACK_TO_ALL_DATA"
            }), 200
        except Exception as fallback_err:
            return jsonify({
                "context": [],
                "success": False,
                "error": str(e)
            }), 500

@chat_bp.route('/embedding', methods=['POST'])
def generate_embedding():
    """Embedding endpoint"""
    try:
        data = request.get_json()
        embedding_request = EmbeddingRequest(**data)
        
        result = ai_service.generate_embedding(embedding_request.text)
        
        response = EmbeddingResponse(
            embedding=result["embedding"],
            success=result["success"],
            error=result.get("error")
        )
        
        return jsonify(response.dict()), 200
        
    except Exception as e:
        logger.error(f"Embedding Controller Error: {e}")
        
        # Fallback embedding
        import numpy as np
        fallback_embedding = list(np.random.random(384))
        
        return jsonify({
            "embedding": fallback_embedding,
            "success": False,
            "error": "EMBEDDING_FALLBACK"
        }), 200 