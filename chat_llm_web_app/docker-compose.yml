version: '3.8'

services:
  nginx:
    image: nginx:alpine
    container_name: nuxt-ai-nginx
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro
    depends_on:
      - nuxt-app
      - ollama
      - qdrant
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  nuxt-app:
    build: .
    container_name: nuxt-ai-app
    expose:
      - "3000"
    environment:
      - NODE_ENV=production
      - MONGODB_URI=mongodb://mongodb:27017/ai_logs
      - QDRANT_URL=http://qdrant:6333
      - OLLAMA_URL=http://ollama:11434/api
      - OLLAMA_CHAT_MODEL=llama3
      - OLLAMA_EMBEDDING_MODEL=all-minilm
      - AI_TEMPERATURE=0.7
      - AI_MAX_TOKENS=512
    depends_on:
      - mongodb
      - qdrant
      - ollama
    restart: unless-stopped

  qdrant:
    image: qdrant/qdrant:latest
    container_name: nuxt-ai-qdrant
    ports:
      - "6333:6333"
      - "6334:6334"
    volumes:
      - qdrant_storage:/qdrant/storage
    environment:
      - QDRANT__SERVICE__HTTP_PORT=6333
      - QDRANT__SERVICE__GRPC_PORT=6334
    restart: unless-stopped

  mongodb:
    image: mongo:latest
    container_name: nuxt-ai-mongodb
    ports:
      - "27017:27017"
    volumes:
      - mongodb_data:/data/db
    environment:
      - MONGO_INITDB_DATABASE=ai_logs
    restart: unless-stopped

  ollama:
    image: ollama/ollama:latest
    container_name: nuxt-ai-ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama_models:/root/.ollama
    environment:
      - OLLAMA_HOST=0.0.0.0
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
      interval: 30s
      timeout: 10s
      retries: 3

volumes:
  qdrant_storage:
    driver: local
  mongodb_data:
    driver: local
  ollama_models:
    driver: local 